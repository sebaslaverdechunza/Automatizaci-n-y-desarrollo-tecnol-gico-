# üìä Validador y Exportador de Anexos (Pregunta 1 ‚Äì Aplicativo de carga y exportaci√≥n)

Aplicativo web sencillo para cargar archivos tabulares (`.csv` o `.xlsx`), validar m√≠nimamente la estructura y exportar un archivo Excel (‚Äúanexo‚Äù) con los datos limpios y un registro de errores.

Este ejercicio corresponde a la **Pregunta 1 ‚Äì Aplicativo de carga y exportaci√≥n**.

---

## üöÄ Instalaci√≥n y ejecuci√≥n

### 1. Clonar o copiar el repositorio
Ub√≠cate en la carpeta de trabajo y crea un entorno virtual:

```bash
python -m venv .venv
```

### 2. Activar el entorno virtual
Windows PowerShell:

```bash
.\.venv\Scripts\Activate.ps1
```
### 3. Instalar dependencias

```bash
pip install -r requirements.txt
```

### 4. Ejecutar el aplicativo

```bash
streamlit run app.py
```

La aplicaci√≥n se abrir√° en tu navegador en:
http://localhost:8501/
---

üñ•Ô∏è Interfaz del aplicativo

+ Subida de archivo (.csv o .xlsx).

+ Si es Excel: detecci√≥n autom√°tica de hojas y selector de cu√°l procesar.

+ Opcionales:

     + Columnas obligatorias: asegura que ciertas variables est√©n presentes.

     + Columnas porcentaje: permite forzar que se validen como %.

+ Bot√≥n Validar y generar anexo.

+ Panel de resultados:

     + Resumen de validaci√≥n.

     + Vista previa (primeras 20 filas).

     + Errores detectados.

     + Bot√≥n de descarga del anexo validado.
 

 ---
 
‚úÖ Pregunta 1 ‚Äì Aplicativo de carga y exportaci√≥n

## üñ•Ô∏è Dise√±o del aplicativo

### Interfaz
- **Input de archivo**: cargar un `.csv` o `.xlsx`.
- **Selector de hoja** (si es Excel; por defecto se usa `Base`).
- **Bot√≥n de validaci√≥n y exportaci√≥n**.
- **Vista previa**: primeras filas del archivo cargado.
- **Bot√≥n de descarga**: genera el anexo Excel con:
  - `Datos_Limpios` ‚Üí tabla con columnas num√©ricas convertidas.
  - `Errores_Validacion` ‚Üí lista de celdas que no pudieron convertirse.

### L√≥gica interna
1. **Carga del archivo** en memoria (con `pandas`).
2. **Detecci√≥n de columnas num√©ricas**: si ‚â•80% de los valores pueden convertirse a n√∫mero.
3. **Conversi√≥n y validaci√≥n**:  
   - Se normalizan separadores de miles/decimales.  
   - Se registran celdas no convertibles indicando fila y columna.  
4. **Exportaci√≥n**: se genera un Excel con dos hojas (datos limpios + errores).

---

## üîé Pseudoc√≥digo

INICIO
  archivo <- subir (.csv | .xlsx)
  si es Excel:
      hoja <- seleccionar (por defecto ‚ÄúBase‚Äù)

  df <- leer_archivo(archivo, hoja)

  clean <- copiar(df)
  errores <- []

  PARA cada columna en df:
    si es num√©rica:
      parsed <- normalizar_y_convertir(columna)
      registrar errores si no convertible
      si columna es porcentaje:
        registrar errores si valor <0 o >100
        guardar como fracci√≥n (Excel %)
      sino:
        guardar como num√©rico

  generar Excel con:
    - Hoja Datos_Limpios
    - Hoja Errores_Validacion
  ofrecer descarga
FIN

 ---

 # üìä Pregunta 2 ‚Äì Diagrama de procesos para la GEIH

Considerando que una operaci√≥n como la **GEIH** pasa por:

    + Recolecci√≥n de datos
    + Carga y validaci√≥n
    + Construcci√≥n de factores de expansi√≥n
    + Generaci√≥n de bases de datos validadas
    + Estimaci√≥n de errores est√°ndar y varianzas
    + Producci√≥n de anexos/tablas de salida

    
üëâ **Pregunta**: Dise√±a un **diagrama de procesos** (puede ser un flujo con cajas y flechas, pseudodiagrama o explicaci√≥n textual detallada) que muestre c√≥mo automatizar√≠as esas fases, identificando:

    - Entradas y salidas de cada fase.
    - Herramientas/lenguajes que usar√≠as (ej. R, Python, SQL, ETL).
    - Puntos cr√≠ticos donde pondr√≠as validaciones autom√°ticas.
---

## **Soluci√≥n:**

Este documento presenta un **bosquejo general** de c√≥mo automatizar el proceso de la **Gran Encuesta Integrada de Hogares (GEIH)**.  
El objetivo no es una implementaci√≥n completa, sino un esquema conceptual que demuestre habilidades de dise√±o de pipelines, mostrando de manera clara:

- Las **fases principales** (recolecci√≥n, validaci√≥n, factores, bases validadas, estimaci√≥n y producci√≥n de anexos).  
- Las **entradas y salidas** de cada fase.  
- Las **herramientas y lenguajes** adecuados (Python, R, SQL, orquestadores ETL).  
- Los **puntos cr√≠ticos de validaci√≥n autom√°tica** donde se asegura la calidad y consistencia de los datos.

---


---

## üöÄ Dise√±o del proceso (flujo general)

```text
[Inicio: Fuentes de Datos Externas]
          |
          v
+----------------------------------+
| Fase 1: Recolecci√≥n de Datos     |
+----------------------------------+
   (Archivos crudos + metadatos)
          |
          v
+----------------------------------+   
| Fase 2: Carga y Validaci√≥n       |  <-- (Vuelve a Fase 1 si falla validaci√≥n)
+----------------------------------+
   (Silver + bit√°cora de calidad)
          |
          v
+----------------------------------+   
| Fase 3: Factores de Expansi√≥n    |   <-- (Vuelve a Fase 2 si factores inconsistentes)
+----------------------------------+
   (Factores calibrados)
          |
          v
+----------------------------------+
| Fase 4: Bases Validadas (Gold)   |
+----------------------------------+
   (Tablas persona/hogar de an√°lisis)
          |
          v
+----------------------------------+  
| Fase 5: EE y Varianzas           |     <-- (Vuelve a Fase 4 si varianzas an√≥malas)
+----------------------------------+
   (Indicadores con EE/CV/IC)
          |
          v
+----------------------------------+
| Fase 6: Anexos / Tablas de Salida|
+----------------------------------+
   (Excel, CSV, dashboards, API)
          |
          v
[Fin: Productos Finales]
```
---

## Resumen del flujo general

| Fase                      | Entradas                                     | Salidas                                                   | Herramientas                      | Validaciones cr√≠ticas                                        |
| ------------------------- | -------------------------------------------- | --------------------------------------------------------- | --------------------------------- | ------------------------------------------------------------ |
| 1. Recolecci√≥n            | Formularios (CAPI/CATI/ODK) + metadatos      | Crudos (CSV/JSON/Parquet), manifiestos                    | ODK/CSPro/SurveyCTO               | Saltos l√≥gicos, rangos duros (edad 0‚Äì110), ocupaci√≥n‚Äìhoras   |
| 2. Carga y validaci√≥n     | Crudos                                       | Bronze (estandarizado), Silver (tipos/llaves), reporte DQ | Python/R, Great Expectations, SQL | Esquema, tipos, IDs √∫nicos, reglas l√≥gicas y geogr√°ficas     |
| 3. Factores de expansi√≥n  | Silver + marco + proyecciones                | Factores base y calibrados (dominio/estrato)              | R `survey` / Python `statsmodels` | Suma pesos ‚âà poblaci√≥n; pesos > 0; estabilidad hist√≥rica     |
| 4. Bases validadas (Gold) | Silver + factores                            | Gold (persona/hogar) + codebook                           | SQL/dbt, pandas/data.table        | Integridad hogar‚Äìpersona; cobertura por dominio; derivadas   |
| 5. EE y Varianzas         | Gold + dise√±o (estrato, UPM, fpc) + factores | Indicadores con EE, CV, IC                                | R `survey` (est√°ndar)             | CV ‚â§ umbrales; n efectivo; coherencia temporal               |
| 6. Anexos / salida        | Indicadores validados                        | Excel/CSV, dashboards, API                                | Python (xlsxwriter/FastAPI), BI   | Formatos (decimales/hojas), totales consistentes, versionado |


---

## üß© Orquestaci√≥n y control

+ **Orquestador**: Airflow o Prefect (DAG mensual con retries y alertas).
+ **Capas de datos**: Bronze ‚Üí Silver ‚Üí Gold (lineage y trazabilidad).
+ **Versionado**: Git para c√≥digo; convenciones de datasets versionados.
+ **Seguridad**: control de accesos y anonimizaci√≥n de microdatos cuando aplique.

---

## <img width="280" height="280" alt="image" src="https://github.com/user-attachments/assets/6ec57bed-b386-492a-82b2-8ceb2eba4c79" /> Pseudodiagrama de automatizaci√≥n (ejemplo con Prefect)

```PYTHON
from prefect import flow, task

@task(retries=2)
def ingest(): return "bronze"

@task
def validate(bronze): return "silver", "dq_report"

@task
def build_weights(silver): return "weights"

@task
def assemble_gold(silver, weights): return "gold"

@task
def estimate(gold): return "indicadores"

@task
def make_annex(indicadores): return "anexos.xlsx"

@flow
def geih_pipeline():
    bronze = ingest()
    silver, dq = validate(bronze)
    weights = build_weights(silver)
    gold = assemble_gold(silver, weights)
    indicadores = estimate(gold)
    anexos = make_annex(indicadores)
    return anexos


## üì• 1. Recolecci√≥n de datos

     Qu√© hace: Enumeradores capturan la informaci√≥n en campo (hogares y personas).
     Entradas: cuestionarios en tablets o formularios web.
     Salidas: archivos crudos (CSV/JSON/Excel) + metadatos (fecha, encuestador, ubicaci√≥n).

- **Entradas**: formularios de campo (CAPI, CATI, ODK, CSPro).  
- **Salidas**: archivos crudos (CSV/JSON/Parquet) + manifiestos (metadatos de enumerador, fecha, GPS).  
- **Herramientas**: sistemas de captura; exportadores a S3/GCS/FTP.  
- **Validaciones cr√≠ticas**:  
  - Saltos l√≥gicos del cuestionario.  
  - Rangos duros (edad 0‚Äì110, personas en hogar ‚â•1).  
  - Consistencia b√°sica (ocupado ‚áí horas>0).  
```


---

## üîç 2. Carga y validaci√≥n

     Qu√© hace: Ingresa los archivos crudos a un sistema de almacenamiento y verifica su calidad.
     Entradas: Archivos crudos.
     Salidas: Datos limpios de primera capa (‚ÄúSilver‚Äù) + reporte de errores.
     Validaciones t√≠picas:
          - Que no falten columnas.
          - Que los IDs sean √∫nicos.
          - Que los valores est√©n en rango (ej. edad no negativa).

- **Entradas**: archivos crudos.  
- **Salidas**:  
  - Capa **Bronze** (crudos estandarizados, inmutables).  
  - Capa **Silver** (con tipos corregidos, claves limpias).  
  - Bit√°cora de errores de calidad.  
- **Herramientas**: Python (pandas), R (data.table), Great Expectations.  
- **Validaciones cr√≠ticas**:  
  - Presencia de columnas esperadas.  
  - Tipos correctos (num√©ricos, strings).  
  - Unicidad de IDs.  
  - Reglas l√≥gicas (ej. menores de 12 no deber√≠an tener ocupaci√≥n).

---

## ‚öñÔ∏è 3. Factores de expansi√≥n

     Qu√© hace: genera pesos para que cada persona/hogar represente a la poblaci√≥n total.
     Entradas: bases limpias + marco muestral + proyecciones de poblaci√≥n.
     Salidas: factores ajustados y calibrados (un n√∫mero por registro).
     Valida: que la suma de factores ‚âà poblaci√≥n oficial.
          
- **Entradas**: base Silver + marco muestral + poblaci√≥n proyectada.  
- **Salidas**: factores base y calibrados por dominio/estrato.  
- **Herramientas**: R (`survey`, `srvyr`), Python (`statsmodels`).  
- **Validaciones cr√≠ticas**:  
  - Suma de pesos ‚âà poblaci√≥n objetivo.  
  - Pesos positivos y razonables.  
  - Comparaci√≥n hist√≥rica de distribuci√≥n de pesos.  

---

## üóÑÔ∏è 4. Bases de datos validadas (Gold)

    Qu√© hace: integra datos de hogares y personas en una base lista para an√°lisis (‚ÄúGold‚Äù).
    Entradas: datos Silver + factores.
    Salidas: tablas finales (hogar/persona) con variables derivadas (ej. tasas de participaci√≥n).
    Valida: consistencia entre hogar y persona, y cobertura por dominios.

- **Entradas**: Silver + factores.  
- **Salidas**: tablas integradas (persona, hogar) listas para an√°lisis.  
- **Herramientas**: Python (pandas), R (data.table), SQL/dbt.  
- **Validaciones cr√≠ticas**:  
  - Integridad hogar-persona.  
  - Cobertura m√≠nima por dominio.  
  - Variables derivadas consistentes (ej. tasas calculadas).  

---

## üìä 5. Estimaci√≥n de errores est√°ndar y varianzas

    Qu√© hace: calcula no solo los indicadores (ej. tasa de desempleo), sino tambi√©n su precisi√≥n (errores est√°ndar, coeficientes de variaci√≥n).
    Entradas: bases Gold + dise√±o muestral (estratos, UPM) + factores.
    Salidas: indicadores con EE y CV por dominio/periodo.
    Valida: que los errores no sean excesivos y que haya casos suficientes por grupo.

- **Entradas**: base Gold + dise√±o muestral (estratos, UPM, fpc) + factores.  
- **Salidas**: indicadores con estimaciones, EE, CV e intervalos de confianza.  
- **Herramientas**: R (`survey`) como est√°ndar; Python (`statsmodels.survey`).  
- **Validaciones cr√≠ticas**:  
  - CV dentro de umbrales.  
  - Casos efectivos por dominio.  
  - Coherencia temporal.  

---

## üìë 6. Producci√≥n de anexos/tablas de salida

    Qu√© hace: genera los productos finales para publicar.
    Entradas: indicadores validados.
    Salidas: Excel, CSV, tableros (Power BI, Metabase) o API para consulta autom√°tica.
    Valida: formatos correctos, totales consistentes, decimales uniformes.

- **Entradas**: indicadores validados.  
- **Salidas**:  
  - Archivos Excel/CSV con tablas oficiales.  
  - Dashboards (Power BI, Metabase).  
  - API (FastAPI) para consulta autom√°tica.  
- **Herramientas**: Python (`xlsxwriter`, FastAPI), R (`openxlsx`, `flextable`).  
- **Validaciones cr√≠ticas**:  
  - Formatos correctos (decimales, nombres de hoja).  
  - Totales y tasas reproducen resultados auditados.  

---

## ‚öôÔ∏è Orquestaci√≥n y control
- **Orquestador**: Airflow o Prefect con DAG mensual.  
- **Monitoreo**: alertas en caso de errores.  
- **Versionado**: Git para c√≥digo; versionado de datasets (Bronze/Silver/Gold).  
- **Seguridad**: control de accesos y anonimizaci√≥n de microdatos.

---

## üß© Pseudodiagrama de automatizaci√≥n (Prefect)

```python
from prefect import flow, task

@task
def ingest(): return "bronze"

@task
def validate(bronze): return "silver", "dq_report"

@task
def build_weights(silver): return "weights"

@task
def assemble_gold(silver, weights): return "gold"

@task
def estimate(gold): return "indicadores"

@task
def make_annex(indicadores): return "anexos.xlsx"

@flow
def geih_pipeline():
    bronze = ingest()
    silver, dq = validate(bronze)
    weights = build_weights(silver)
    gold = assemble_gold(silver, weights)
    indicadores = estimate(gold)
    anexos = make_annex(indicadores)
    return anexos
```
